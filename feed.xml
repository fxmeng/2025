<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://iclr-blogposts.github.io/2025/feed.xml" rel="self" type="application/atom+xml"/><link href="https://iclr-blogposts.github.io/2025/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-11-24T00:13:00+08:00</updated><id>https://iclr-blogposts.github.io/2025/feed.xml</id><title type="html">ICLR Blogposts 2025</title><subtitle>Home to the 2025 ICLR Blogposts track </subtitle><entry><title type="html">Sample Blog Post</title><link href="https://iclr-blogposts.github.io/2025/blog/distill-example/" rel="alternate" type="text/html" title="Sample Blog Post"/><published>2025-04-28T00:00:00+08:00</published><updated>2025-04-28T00:00:00+08:00</updated><id>https://iclr-blogposts.github.io/2025/blog/distill-example</id><content type="html" xml:base="https://iclr-blogposts.github.io/2025/blog/distill-example/"><![CDATA[<p>Note: please use the table of contents as defined in the front matter rather than the traditional markdown styling.</p> <h2 id="equations">Equations</h2> <p>This theme supports rendering beautiful math in inline and display modes using <a href="https://www.mathjax.org/">MathJax 3</a> engine. You just need to surround your math expression with <code class="language-plaintext highlighter-rouge">$$</code>, like <code class="language-plaintext highlighter-rouge">$$ E = mc^2 $$</code>. If you leave it inside a paragraph, it will produce an inline expression, just like \(E = mc^2\).</p> <p>To use display mode, again surround your expression with <code class="language-plaintext highlighter-rouge">$$</code> and place it as a separate paragraph. Here is an example:</p> \[\left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right)\] <p>Note that MathJax 3 is <a href="https://docs.mathjax.org/en/latest/upgrading/whats-new-3.0.html">a major re-write of MathJax</a> that brought a significant improvement to the loading and rendering speed, which is now <a href="http://www.intmath.com/cg5/katex-mathjax-comparison.php">on par with KaTeX</a>.</p> <h2 id="images-and-figures">Images and Figures</h2> <p>Its generally a better idea to avoid linking to images hosted elsewhere - links can break and you might face losing important information in your blog post. To include images in your submission in this way, you must do something like the following:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{% include figure.html path="assets/img/2025-04-28-distill-example/iclr.png" class="img-fluid" %}
</code></pre></div></div> <p>which results in the following image:</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-distill-example/iclr-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-distill-example/iclr-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-distill-example/iclr-1400.webp"/> <img src="/2025/assets/img/2025-04-28-distill-example/iclr.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>To ensure that there are no namespace conflicts, you must save your asset to your unique directory <code class="language-plaintext highlighter-rouge">/assets/img/2025-04-28-[SUBMISSION NAME]</code> within your submission.</p> <p>Please avoid using the direct markdown method of embedding images; they may not be properly resized. Some more complex ways to load images (note the different styles of the shapes/shadows):</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-distill-example/9-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-distill-example/9-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-distill-example/9-1400.webp"/> <img src="/2025/assets/img/2025-04-28-distill-example/9.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-distill-example/7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-distill-example/7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-distill-example/7-1400.webp"/> <img src="/2025/assets/img/2025-04-28-distill-example/7.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A simple, elegant caption looks good between image rows, after each row, or doesn't have to be there at all. </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-distill-example/8-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-distill-example/8-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-distill-example/8-1400.webp"/> <img src="/2025/assets/img/2025-04-28-distill-example/8.jpg" class="img-fluid z-depth-2" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-distill-example/10-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-distill-example/10-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-distill-example/10-1400.webp"/> <img src="/2025/assets/img/2025-04-28-distill-example/10.jpg" class="img-fluid z-depth-2" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-distill-example/11-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-distill-example/11-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-distill-example/11-1400.webp"/> <img src="/2025/assets/img/2025-04-28-distill-example/11.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-distill-example/12-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-distill-example/12-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-distill-example/12-1400.webp"/> <img src="/2025/assets/img/2025-04-28-distill-example/12.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-distill-example/7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-distill-example/7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-distill-example/7-1400.webp"/> <img src="/2025/assets/img/2025-04-28-distill-example/7.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h3 id="interactive-figures">Interactive Figures</h3> <p>Here’s how you could embed interactive figures that have been exported as HTML files. Note that we will be using plotly for this demo, but anything built off of HTML should work (<strong>no extra javascript is allowed!</strong>). All that’s required is for you to export your figure into HTML format, and make sure that the file exists in the <code class="language-plaintext highlighter-rouge">assets/html/[SUBMISSION NAME]/</code> directory in this repository’s root directory. To embed it into any page, simply insert the following code anywhere into your page.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{% include [FIGURE_NAME].html %} 
</code></pre></div></div> <p>For example, the following code can be used to generate the figure underneath it.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">plotly.express</span> <span class="k">as</span> <span class="n">px</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv</span><span class="sh">'</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="p">.</span><span class="nf">density_mapbox</span><span class="p">(</span>
    <span class="n">df</span><span class="p">,</span> <span class="n">lat</span><span class="o">=</span><span class="sh">'</span><span class="s">Latitude</span><span class="sh">'</span><span class="p">,</span> <span class="n">lon</span><span class="o">=</span><span class="sh">'</span><span class="s">Longitude</span><span class="sh">'</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="sh">'</span><span class="s">Magnitude</span><span class="sh">'</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">center</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span><span class="n">lat</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lon</span><span class="o">=</span><span class="mi">180</span><span class="p">),</span> <span class="n">zoom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mapbox_style</span><span class="o">=</span><span class="sh">"</span><span class="s">stamen-terrain</span><span class="sh">"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">write_html</span><span class="p">(</span><span class="sh">'</span><span class="s">./assets/html/2025-04-28-distill-example/plotly_demo_1.html</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>And then include it with the following:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"l-page"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;iframe</span> <span class="na">src=</span><span class="s">"{{ 'assets/html/2025-04-28-distill-example/plotly_demo_1.html' | relative_url }}"</span> <span class="na">frameborder=</span><span class="s">'0'</span> <span class="na">scrolling=</span><span class="s">'no'</span> <span class="na">height=</span><span class="s">"600px"</span> <span class="na">width=</span><span class="s">"100%"</span><span class="nt">&gt;&lt;/iframe&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> <p>Voila!</p> <div class="l-page"> <iframe src="/2025/assets/html/2025-04-28-distill-example/plotly_demo_1.html" frameborder="0" scrolling="no" height="600px" width="100%"></iframe> </div> <h2 id="citations">Citations</h2> <p>Citations are then used in the article body with the <code class="language-plaintext highlighter-rouge">&lt;d-cite&gt;</code> tag. The key attribute is a reference to the id provided in the bibliography. The key attribute can take multiple ids, separated by commas.</p> <p>The citation is presented inline like this: <d-cite key="gregor2015draw"></d-cite> (a number that displays more information on hover). If you have an appendix, a bibliography is automatically created and populated in it.</p> <p>Distill chose a numerical inline citation style to improve readability of citation dense articles and because many of the benefits of longer citations are obviated by displaying more information on hover. However, we consider it good style to mention author last names if you discuss something at length and it fits into the flow well — the authors are human and it’s nice for them to have the community associate them with their work.</p> <hr/> <h2 id="footnotes">Footnotes</h2> <p>Just wrap the text you would like to show up in a footnote in a <code class="language-plaintext highlighter-rouge">&lt;d-footnote&gt;</code> tag. The number of the footnote will be automatically generated.<d-footnote>This will become a hoverable footnote.</d-footnote></p> <hr/> <h2 id="code-blocks">Code Blocks</h2> <p>This theme implements a built-in Jekyll feature, the use of Rouge, for syntax highlighting. It supports more than 100 languages. This example is in C++. All you have to do is wrap your code in a liquid tag:</p> <p>{% highlight c++ linenos %} <br/> code code code <br/> {% endhighlight %}</p> <p>The keyword <code class="language-plaintext highlighter-rouge">linenos</code> triggers display of line numbers. You can try toggling it on or off yourself below:</p> <figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="k">const</span> <span class="err">\</span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
<span class="n">string</span> <span class="n">myString</span><span class="p">;</span>

    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"input a string: "</span><span class="p">;</span>
    <span class="n">getline</span><span class="p">(</span><span class="n">cin</span><span class="p">,</span> <span class="n">myString</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">length</span> <span class="o">=</span> <span class="n">myString</span><span class="p">.</span><span class="n">length</span><span class="p">();</span>

    <span class="kt">char</span> <span class="n">charArray</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">char</span> <span class="o">*</span> <span class="p">[</span><span class="n">length</span><span class="p">];</span>

    <span class="n">charArray</span> <span class="o">=</span> <span class="n">myString</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">length</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">){</span>
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">charArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">" "</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure> <hr/> <h2 id="diagrams">Diagrams</h2> <p>This theme supports generating various diagrams from a text description using <a href="https://github.com/zhustec/jekyll-diagrams" target="\_blank">jekyll-diagrams</a> plugin. Below, we generate a few examples of such diagrams using languages such as <a href="https://mermaid-js.github.io/mermaid/" target="\_blank">mermaid</a>, <a href="https://plantuml.com/" target="\_blank">plantuml</a>, <a href="https://vega.github.io/vega-lite/" target="\_blank">vega-lite</a>, etc.</p> <p><strong>Note:</strong> different diagram-generation packages require external dependencies to be installed on your machine. Also, be mindful of that because of diagram generation the first time you build your Jekyll website after adding new diagrams will be SLOW. For any other details, please refer to <a href="https://github.com/zhustec/jekyll-diagrams" target="\_blank">jekyll-diagrams</a> README.</p> <p><strong>Note:</strong> This is not supported for local rendering!</p> <p>The diagram below was generated by the following code:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{% mermaid %}
sequenceDiagram
    participant John
    participant Alice
    Alice-&gt;&gt;John: Hello John, how are you?
    John--&gt;&gt;Alice: Great!
{% endmermaid %}
</code></pre></div></div> <div class="jekyll-diagrams diagrams mermaid"> <svg id="mermaid-1732378387099" width="100%" xmlns="http://www.w3.org/2000/svg" height="100%" style="max-width:450px;" viewBox="-50 -10 450 231"><style>#mermaid-1732378387099 .label{font-family:trebuchet ms,verdana,arial;color:#333}#mermaid-1732378387099 .node circle,#mermaid-1732378387099 .node ellipse,#mermaid-1732378387099 .node polygon,#mermaid-1732378387099 .node rect{fill:#ececff;stroke:#9370db;stroke-width:1px}#mermaid-1732378387099 .node.clickable{cursor:pointer}#mermaid-1732378387099 .arrowheadPath{fill:#333}#mermaid-1732378387099 .edgePath .path{stroke:#333;stroke-width:1.5px}#mermaid-1732378387099 .edgeLabel{background-color:#e8e8e8}#mermaid-1732378387099 .cluster rect{fill:#ffffde!important;stroke:#aa3!important;stroke-width:1px!important}#mermaid-1732378387099 .cluster text{fill:#333}#mermaid-1732378387099 div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:trebuchet ms,verdana,arial;font-size:12px;background:#ffffde;border:1px solid #aa3;border-radius:2px;pointer-events:none;z-index:100}#mermaid-1732378387099 .actor{stroke:#ccf;fill:#ececff}#mermaid-1732378387099 text.actor{fill:#000;stroke:none}#mermaid-1732378387099 .actor-line{stroke:grey}#mermaid-1732378387099 .messageLine0{marker-end:"url(#arrowhead)"}#mermaid-1732378387099 .messageLine0,#mermaid-1732378387099 .messageLine1{stroke-width:1.5;stroke-dasharray:"2 2";stroke:#333}#mermaid-1732378387099 #arrowhead{fill:#333}#mermaid-1732378387099 #crosshead path{fill:#333!important;stroke:#333!important}#mermaid-1732378387099 .messageText{fill:#333;stroke:none}#mermaid-1732378387099 .labelBox{stroke:#ccf;fill:#ececff}#mermaid-1732378387099 .labelText,#mermaid-1732378387099 .loopText{fill:#000;stroke:none}#mermaid-1732378387099 .loopLine{stroke-width:2;stroke-dasharray:"2 2";marker-end:"url(#arrowhead)";stroke:#ccf}#mermaid-1732378387099 .note{stroke:#aa3;fill:#fff5ad}#mermaid-1732378387099 .noteText{fill:#000;stroke:none;font-family:trebuchet ms,verdana,arial;font-size:14px}#mermaid-1732378387099 .section{stroke:none;opacity:.2}#mermaid-1732378387099 .section0{fill:rgba(102,102,255,.49)}#mermaid-1732378387099 .section2{fill:#fff400}#mermaid-1732378387099 .section1,#mermaid-1732378387099 .section3{fill:#fff;opacity:.2}#mermaid-1732378387099 .sectionTitle0,#mermaid-1732378387099 .sectionTitle1,#mermaid-1732378387099 .sectionTitle2,#mermaid-1732378387099 .sectionTitle3{fill:#333}#mermaid-1732378387099 .sectionTitle{text-anchor:start;font-size:11px;text-height:14px}#mermaid-1732378387099 .grid .tick{stroke:#d3d3d3;opacity:.3;shape-rendering:crispEdges}#mermaid-1732378387099 .grid path{stroke-width:0}#mermaid-1732378387099 .today{fill:none;stroke:red;stroke-width:2px}#mermaid-1732378387099 .task{stroke-width:2}#mermaid-1732378387099 .taskText{text-anchor:middle;font-size:11px}#mermaid-1732378387099 .taskTextOutsideRight{fill:#000;text-anchor:start;font-size:11px}#mermaid-1732378387099 .taskTextOutsideLeft{fill:#000;text-anchor:end;font-size:11px}#mermaid-1732378387099 .taskText0,#mermaid-1732378387099 .taskText1,#mermaid-1732378387099 .taskText2,#mermaid-1732378387099 .taskText3{fill:#fff}#mermaid-1732378387099 .task0,#mermaid-1732378387099 .task1,#mermaid-1732378387099 .task2,#mermaid-1732378387099 .task3{fill:#8a90dd;stroke:#534fbc}#mermaid-1732378387099 .taskTextOutside0,#mermaid-1732378387099 .taskTextOutside1,#mermaid-1732378387099 .taskTextOutside2,#mermaid-1732378387099 .taskTextOutside3{fill:#000}#mermaid-1732378387099 .active0,#mermaid-1732378387099 .active1,#mermaid-1732378387099 .active2,#mermaid-1732378387099 .active3{fill:#bfc7ff;stroke:#534fbc}#mermaid-1732378387099 .activeText0,#mermaid-1732378387099 .activeText1,#mermaid-1732378387099 .activeText2,#mermaid-1732378387099 .activeText3{fill:#000!important}#mermaid-1732378387099 .done0,#mermaid-1732378387099 .done1,#mermaid-1732378387099 .done2,#mermaid-1732378387099 .done3{stroke:grey;fill:#d3d3d3;stroke-width:2}#mermaid-1732378387099 .doneText0,#mermaid-1732378387099 .doneText1,#mermaid-1732378387099 .doneText2,#mermaid-1732378387099 .doneText3{fill:#000!important}#mermaid-1732378387099 .crit0,#mermaid-1732378387099 .crit1,#mermaid-1732378387099 .crit2,#mermaid-1732378387099 .crit3{stroke:#f88;fill:red;stroke-width:2}#mermaid-1732378387099 .activeCrit0,#mermaid-1732378387099 .activeCrit1,#mermaid-1732378387099 .activeCrit2,#mermaid-1732378387099 .activeCrit3{stroke:#f88;fill:#bfc7ff;stroke-width:2}#mermaid-1732378387099 .doneCrit0,#mermaid-1732378387099 .doneCrit1,#mermaid-1732378387099 .doneCrit2,#mermaid-1732378387099 .doneCrit3{stroke:#f88;fill:#d3d3d3;stroke-width:2;cursor:pointer;shape-rendering:crispEdges}#mermaid-1732378387099 .activeCritText0,#mermaid-1732378387099 .activeCritText1,#mermaid-1732378387099 .activeCritText2,#mermaid-1732378387099 .activeCritText3,#mermaid-1732378387099 .doneCritText0,#mermaid-1732378387099 .doneCritText1,#mermaid-1732378387099 .doneCritText2,#mermaid-1732378387099 .doneCritText3{fill:#000!important}#mermaid-1732378387099 .titleText{text-anchor:middle;font-size:18px;fill:#000}
#mermaid-1732378387099 g.classGroup text{fill:#9370db;stroke:none;font-family:trebuchet ms,verdana,arial;font-size:10px}#mermaid-1732378387099 g.classGroup rect{fill:#ececff;stroke:#9370db}#mermaid-1732378387099 g.classGroup line{stroke:#9370db;stroke-width:1}#mermaid-1732378387099 .classLabel .box{stroke:none;stroke-width:0;fill:#ececff;opacity:.5}#mermaid-1732378387099 .classLabel .label{fill:#9370db;font-size:10px}#mermaid-1732378387099 .relation{stroke:#9370db;stroke-width:1;fill:none}#mermaid-1732378387099 #compositionEnd,#mermaid-1732378387099 #compositionStart{fill:#9370db;stroke:#9370db;stroke-width:1}#mermaid-1732378387099 #aggregationEnd,#mermaid-1732378387099 #aggregationStart{fill:#ececff;stroke:#9370db;stroke-width:1}#mermaid-1732378387099 #dependencyEnd,#mermaid-1732378387099 #dependencyStart,#mermaid-1732378387099 #extensionEnd,#mermaid-1732378387099 #extensionStart{fill:#9370db;stroke:#9370db;stroke-width:1}#mermaid-1732378387099 .branch-label,#mermaid-1732378387099 .commit-id,#mermaid-1732378387099 .commit-msg{fill:#d3d3d3;color:#d3d3d3}</style><style>#mermaid-1732378387099{color:#000;font:normal normal 400 normal 16px / normal "Times New Roman"}</style><g></g><g><line id="actor0" x1="75" y1="5" x2="75" y2="220" class="actor-line" stroke-width="0.5px" stroke="#999"></line><rect x="0" y="0" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="75" y="32.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="75" dy="0">John</tspan></text></g><g><line id="actor1" x1="275" y1="5" x2="275" y2="220" class="actor-line" stroke-width="0.5px" stroke="#999"></line><rect x="200" y="0" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="275" y="32.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="275" dy="0">Alice</tspan></text></g><defs><marker id="arrowhead" refX="5" refY="2" markerWidth="6" markerHeight="4" orient="auto"><path d="M 0,0 V 4 L6,2 Z"></path></marker></defs><defs><marker id="crosshead" markerWidth="15" markerHeight="8" orient="auto" refX="16" refY="4"><path fill="black" stroke="#000000" stroke-width="1px" d="M 9,2 V 6 L16,4 Z" style="stroke-dasharray: 0, 0;"></path><path fill="none" stroke="#000000" stroke-width="1px" d="M 0,1 L 6,7 M 6,1 L 0,7" style="stroke-dasharray: 0, 0;"></path></marker></defs><g><text x="175" y="93" class="messageText" style="text-anchor: middle;">Hello John, how are you?</text><line x1="275" y1="100" x2="75" y2="100" class="messageLine0" stroke-width="2" stroke="black" marker-end="url(#arrowhead)" style="fill: none;"></line></g><g><text x="175" y="128" class="messageText" style="text-anchor: middle;">Great!</text><line x1="75" y1="135" x2="275" y2="135" class="messageLine1" stroke-width="2" stroke="black" marker-end="url(#arrowhead)" style="stroke-dasharray: 3, 3; fill: none;"></line></g><g><rect x="0" y="155" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="75" y="187.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="75" dy="0">John</tspan></text></g><g><rect x="200" y="155" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="275" y="187.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="275" dy="0">Alice</tspan></text></g></svg> </div> <hr/> <h2 id="tweets">Tweets</h2> <p>An example of displaying a tweet:</p> <div class="jekyll-twitter-plugin"><blockquote class="twitter-tweet"><p lang="sv" dir="ltr">jekyll-twitter-plugin (1.0.0): A Liquid tag plugin for Jekyll that renders Tweets from Twitter API <a href="http://t.co/m4EIQPM9h4">http://t.co/m4EIQPM9h4</a></p>&mdash; RubyGems (@rubygems) <a href="https://twitter.com/rubygems/status/518821243320287232?ref_src=twsrc%5Etfw">October 5, 2014</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> <p>An example of pulling from a timeline:</p> <div class="jekyll-twitter-plugin"><a class="twitter-timeline" data-width="500" data-tweet-limit="3" href="https://twitter.com/jekyllrb?ref_src=twsrc%5Etfw">Tweets by jekyllrb</a> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> <p>For more details on using the plugin visit: <a href="https://github.com/rob-murray/jekyll-twitter-plugin">jekyll-twitter-plugin</a></p> <hr/> <h2 id="blockquotes">Blockquotes</h2> <blockquote> We do not grow absolutely, chronologically. We grow sometimes in one dimension, and not in another, unevenly. We grow partially. We are relative. We are mature in one realm, childish in another. —Anais Nin </blockquote> <hr/> <h2 id="layouts">Layouts</h2> <p>The main text column is referred to as the body. It is the assumed layout of any direct descendants of the <code class="language-plaintext highlighter-rouge">d-article</code> element.</p> <div class="fake-img l-body"> <p>.l-body</p> </div> <p>For images you want to display a little larger, try <code class="language-plaintext highlighter-rouge">.l-page</code>:</p> <div class="fake-img l-page"> <p>.l-page</p> </div> <p>All of these have an outset variant if you want to poke out from the body text a little bit. For instance:</p> <div class="fake-img l-body-outset"> <p>.l-body-outset</p> </div> <div class="fake-img l-page-outset"> <p>.l-page-outset</p> </div> <p>Occasionally you’ll want to use the full browser width. For this, use <code class="language-plaintext highlighter-rouge">.l-screen</code>. You can also inset the element a little from the edge of the browser by using the inset variant.</p> <div class="fake-img l-screen"> <p>.l-screen</p> </div> <div class="fake-img l-screen-inset"> <p>.l-screen-inset</p> </div> <p>The final layout is for marginalia, asides, and footnotes. It does not interrupt the normal flow of <code class="language-plaintext highlighter-rouge">.l-body</code>-sized text except on mobile screen sizes.</p> <div class="fake-img l-gutter"> <p>.l-gutter</p> </div> <hr/> <h2 id="other-typography">Other Typography?</h2> <p>Emphasis, aka italics, with <em>asterisks</em> (<code class="language-plaintext highlighter-rouge">*asterisks*</code>) or <em>underscores</em> (<code class="language-plaintext highlighter-rouge">_underscores_</code>).</p> <p>Strong emphasis, aka bold, with <strong>asterisks</strong> or <strong>underscores</strong>.</p> <p>Combined emphasis with <strong>asterisks and <em>underscores</em></strong>.</p> <p>Strikethrough uses two tildes. <del>Scratch this.</del></p> <ol> <li>First ordered list item</li> <li>Another item ⋅⋅* Unordered sub-list.</li> <li>Actual numbers don’t matter, just that it’s a number ⋅⋅1. Ordered sub-list</li> <li>And another item.</li> </ol> <p>⋅⋅⋅You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we’ll use three here to also align the raw Markdown).</p> <p>⋅⋅⋅To have a line break without a paragraph, you will need to use two trailing spaces.⋅⋅ ⋅⋅⋅Note that this line is separate, but within the same paragraph.⋅⋅ ⋅⋅⋅(This is contrary to the typical GFM line break behavior, where trailing spaces are not required.)</p> <ul> <li>Unordered lists can use asterisks</li> <li>Or minuses</li> <li>Or pluses</li> </ul> <p><a href="https://www.google.com">I’m an inline-style link</a></p> <p><a href="https://www.google.com" title="Google's Homepage">I’m an inline-style link with title</a></p> <p><a href="https://www.mozilla.org">I’m a reference-style link</a></p> <p><a href="../blob/master/LICENSE">I’m a relative reference to a repository file</a></p> <p><a href="http://slashdot.org">You can use numbers for reference-style link definitions</a></p> <p>Or leave it empty and use the <a href="http://www.reddit.com">link text itself</a>.</p> <p>URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or <a href="http://www.example.com">http://www.example.com</a> and sometimes example.com (but not on Github, for example).</p> <p>Some text to show that the reference links can follow later.</p> <p>Here’s our logo (hover to see the title text):</p> <p>Inline-style: <img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 1"/></p> <p>Reference-style: <img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 2"/></p> <p>Inline <code class="language-plaintext highlighter-rouge">code</code> has <code class="language-plaintext highlighter-rouge">back-ticks around</code> it.</p> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">var</span> <span class="nx">s</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">JavaScript syntax highlighting</span><span class="dl">"</span><span class="p">;</span>
<span class="nf">alert</span><span class="p">(</span><span class="nx">s</span><span class="p">);</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Python syntax highlighting</span><span class="sh">"</span>
<span class="nf">print</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No language indicated, so no syntax highlighting. 
But let's throw in a &lt;b&gt;tag&lt;/b&gt;.
</code></pre></div></div> <p>Colons can be used to align columns.</p> <table> <thead> <tr> <th>Tables</th> <th style="text-align: center">Are</th> <th style="text-align: right">Cool</th> </tr> </thead> <tbody> <tr> <td>col 3 is</td> <td style="text-align: center">right-aligned</td> <td style="text-align: right">$1600</td> </tr> <tr> <td>col 2 is</td> <td style="text-align: center">centered</td> <td style="text-align: right">$12</td> </tr> <tr> <td>zebra stripes</td> <td style="text-align: center">are neat</td> <td style="text-align: right">$1</td> </tr> </tbody> </table> <p>There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don’t need to make the raw Markdown line up prettily. You can also use inline Markdown.</p> <table> <thead> <tr> <th>Markdown</th> <th>Less</th> <th>Pretty</th> </tr> </thead> <tbody> <tr> <td><em>Still</em></td> <td><code class="language-plaintext highlighter-rouge">renders</code></td> <td><strong>nicely</strong></td> </tr> <tr> <td>1</td> <td>2</td> <td>3</td> </tr> </tbody> </table> <blockquote> <p>Blockquotes are very handy in email to emulate reply text. This line is part of the same quote.</p> </blockquote> <p>Quote break.</p> <blockquote> <p>This is a very long line that will still be quoted properly when it wraps. Oh boy let’s keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can <em>put</em> <strong>Markdown</strong> into a blockquote.</p> </blockquote> <p>Here’s a line for us to start with.</p> <p>This line is separated from the one above by two newlines, so it will be a <em>separate paragraph</em>.</p> <p>This line is also a separate paragraph, but… This line is only separated by a single newline, so it’s a separate line in the <em>same paragraph</em>.</p>]]></content><author><name>Albert Einstein</name></author><summary type="html"><![CDATA[Your blog post's abstract. Please add your abstract or summary here and not in the main body of your text. Do not include math/latex or hyperlinks.]]></summary></entry><entry><title type="html">Sample Blog Post (HTML version)</title><link href="https://iclr-blogposts.github.io/2025/blog/distill-example2/" rel="alternate" type="text/html" title="Sample Blog Post (HTML version)"/><published>2025-04-28T00:00:00+08:00</published><updated>2025-04-28T00:00:00+08:00</updated><id>https://iclr-blogposts.github.io/2025/blog/distill-example2</id><content type="html" xml:base="https://iclr-blogposts.github.io/2025/blog/distill-example2/"><![CDATA[<p> This is a sample blog post written in HTML (while the other <a href="/2025/blog/distill-example/">sample post</a> is written in Markdown). Authors have the choice to write in HTML or Markdown. While Markdown is easier to write, HTML gives you more control over the layout of your post. Furthermore, Markdown often interacts in unexpected ways with MathJax and other HTML widgets. If you are having trouble with Markdown, try writing in HTML instead. </p> <p> Note: please use the table of contents as defined in the front matter rather than the traditional markdown styling. </p> <h2 id="equations">Equations</h2> <p>This theme supports rendering beautiful math in inline and display modes using <a href="https://www.mathjax.org/">MathJax 3</a> engine. You just need to surround your math expression with <code>$$</code>, like <code>$$ E = mc^2 $$</code>. If you leave it inside a paragraph, it will produce an inline expression, just like \(E = mc^2\).</p> <p>To use display mode, again surround your expression with <code>$$</code> and place it as a separate paragraph. Here is an example: $$ \left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right) $$ </p> <p>Note that MathJax 3 is <a href="https://docs.mathjax.org/en/latest/upgrading/whats-new-3.0.html">a major re-write of MathJax</a> that brought a significant improvement to the loading and rendering speed, which is now <a href="http://www.intmath.com/cg5/katex-mathjax-comparison.php">on par with KaTeX</a>.</p> <h2 id="images-and-figures">Images and Figures</h2> <p>Its generally a better idea to avoid linking to images hosted elsewhere - links can break and you might face losing important information in your blog post. You can display images from this repository using the following code:</p> <pre><code>{% include figure.html path="assets/img/2025-04-28-distill-example/iclr.png" class="img-fluid" %}</code></pre> <p>which results in the following image:</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-distill-example/iclr-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-distill-example/iclr-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-distill-example/iclr-1400.webp"/> <img src="/2025/assets/img/2025-04-28-distill-example/iclr.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p> To ensure that there are no namespace conflicts, you must save your asset to your unique directory `/assets/img/2025-04-28-[SUBMISSION NAME]` within your submission. </p> <p> Please avoid using the direct HTML method of embedding images; they may not be properly resized. Some below complex ways to load images (note the different styles of the shapes/shadows): </p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-distill-example/9-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-distill-example/9-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-distill-example/9-1400.webp"/> <img src="/2025/assets/img/2025-04-28-distill-example/9.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-distill-example/7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-distill-example/7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-distill-example/7-1400.webp"/> <img src="/2025/assets/img/2025-04-28-distill-example/7.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A simple, elegant caption looks good between image rows, after each row, or doesn't have to be there at all. </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-distill-example/8-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-distill-example/8-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-distill-example/8-1400.webp"/> <img src="/2025/assets/img/2025-04-28-distill-example/8.jpg" class="img-fluid z-depth-2" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-distill-example/10-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-distill-example/10-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-distill-example/10-1400.webp"/> <img src="/2025/assets/img/2025-04-28-distill-example/10.jpg" class="img-fluid z-depth-2" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-distill-example/11-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-distill-example/11-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-distill-example/11-1400.webp"/> <img src="/2025/assets/img/2025-04-28-distill-example/11.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-distill-example/12-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-distill-example/12-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-distill-example/12-1400.webp"/> <img src="/2025/assets/img/2025-04-28-distill-example/12.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-distill-example/7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-distill-example/7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-distill-example/7-1400.webp"/> <img src="/2025/assets/img/2025-04-28-distill-example/7.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h3>Interactive Figures</h3> <p> Here's how you could embed interactive figures that have been exported as HTML files. Note that we will be using plotly for this demo, but anything built off of HTML should work. All that's required is for you to export your figure into HTML format, and make sure that the file exists in the `assets/html/[SUBMISSION NAME]/` directory in this repository's root directory. To embed it into any page, simply insert the following code anywhere into your page. </p> <pre><code>{% include [FIGURE_NAME].html %}</code></pre> <p> For example, the following code can be used to generate the figure underneath it. </p> <pre><code class="language-python">import pandas as pd
import plotly.express as px

df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv')

fig = px.density_mapbox(
    df, lat='Latitude', lon='Longitude', z='Magnitude', radius=10,
    center=dict(lat=0, lon=180), zoom=0, mapbox_style="stamen-terrain")
fig.show()

fig.write_html('./assets/html/2025-04-28-distill-example/plotly_demo_1.html')
</code></pre> And then include it with the following: <pre><code class="language-html">&lt;div class="l-page"&gt;
  &lt;iframe src="{{ 'assets/html/2025-04-28-distill-example/plotly_demo_1.html' | relative_url }}" frameborder='0' scrolling='no' height="600px" width="100%"&gt;&lt;/iframe&gt;
&lt;/div&gt;
</code></pre> Voila! <div class="l-page"> <iframe src="/2025/assets/html/2025-04-28-distill-example/plotly_demo_1.html" frameborder='0' scrolling='no' height="600px" width="100%"></iframe> </div> <h2 id="citations">Citations</h2> <p> Citations are then used in the article body with the <code>&lt;d-cite&gt;</code> tag. The key attribute is a reference to the id provided in the bibliography. The key attribute can take multiple ids, separated by commas. </p> <p> The citation is presented inline like this: <d-cite key="gregor2015draw"></d-cite> (a number that displays more information on hover). If you have an appendix, a bibliography is automatically created and populated in it. </p> <p> Distill chose a numerical inline citation style to improve readability of citation dense articles and because many of the benefits of longer citations are obviated by displaying more information on hover. However, we consider it good style to mention author last names if you discuss something at length and it fits into the flow well - the authors are human and it's nice for them to have the community associate them with their work. </p> <h2 id="footnotes">Footnotes</h2> <p> Just wrap the text you would like to show up in a footnote in a <code>&lt;d-footnote&gt;</code> tag. The number of the footnote will be automatically generated.<d-footnote>This will become a hoverable footnote.</d-footnote> </p> <h2 id="code-blocks">Code Blocks</h2> <p> This theme implements a built-in Jekyll feature, the use of Rouge, for syntax highlighting. It supports more than 100 languages. This example is in C++. All you have to do is wrap your code in a liquid tag as follows: </p> <pre><code>
{% highlight c++ linenos %}  <br/> code code code <br/> {% endhighlight %}

</code></pre> The keyword `linenos` triggers display of line numbers. You can try toggling it on or off yourself below: <figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="k">const</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
<span class="n">string</span> <span class="n">myString</span><span class="p">;</span>

    <span class="n">cout</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="s">"input a string: "</span><span class="p">;</span>
    <span class="n">getline</span><span class="p">(</span><span class="n">cin</span><span class="p">,</span> <span class="n">myString</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">length</span> <span class="o">=</span> <span class="n">myString</span><span class="p">.</span><span class="n">length</span><span class="p">();</span>

    <span class="kt">char</span> <span class="n">charArray</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">char</span> <span class="o">*</span> <span class="p">[</span><span class="n">length</span><span class="p">];</span>

    <span class="n">charArray</span> <span class="o">=</span> <span class="n">myString</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">length</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">){</span>
        <span class="n">cout</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="n">charArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="s">" "</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure> <h2 id="diagrams">Diagrams</h2> <p> This theme supports generating various diagrams from a text description using <a href="https://github.com/zhustec/jekyll-diagrams">jekyll-diagrams</a> plugin. Below, we generate a few examples of such diagrams using languages such as <a href="http://mermaid.js.org/">mermaid</a>, <a href="https://plantuml.com/">plantuml</a>, <a href="https://vega.github.io/vega-lite/">vega-lite</a>, etc. </p> <p> <b>Note</b>different diagram-generation packages require external dependencies to be installed on your machine. Also, be mindful of that because of diagram generation the first time you build your Jekyll website after adding new diagrams will be SLOW. For any other details, please refer to the <a href="https://github.com/zhustec/jekyll-diagrams">jekyll-diagrams</a> README. </p> <p> <b>Note:</b> This is not supported for local rendering! </p> <p> The diagram below was generated by the following code: </p> <pre><code>{% mermaid %}
sequenceDiagram
    participant John
    participant Alice
    Alice->>John: Hello John, how are you?
    John-->>Alice: Great!
{% endmermaid %}

</code></pre> <div class='jekyll-diagrams diagrams mermaid'> <svg id="mermaid-1732378387752" width="100%" xmlns="http://www.w3.org/2000/svg" height="100%" style="max-width:450px;" viewBox="-50 -10 450 231"><style>#mermaid-1732378387752 .label{font-family:trebuchet ms,verdana,arial;color:#333}#mermaid-1732378387752 .node circle,#mermaid-1732378387752 .node ellipse,#mermaid-1732378387752 .node polygon,#mermaid-1732378387752 .node rect{fill:#ececff;stroke:#9370db;stroke-width:1px}#mermaid-1732378387752 .node.clickable{cursor:pointer}#mermaid-1732378387752 .arrowheadPath{fill:#333}#mermaid-1732378387752 .edgePath .path{stroke:#333;stroke-width:1.5px}#mermaid-1732378387752 .edgeLabel{background-color:#e8e8e8}#mermaid-1732378387752 .cluster rect{fill:#ffffde!important;stroke:#aa3!important;stroke-width:1px!important}#mermaid-1732378387752 .cluster text{fill:#333}#mermaid-1732378387752 div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:trebuchet ms,verdana,arial;font-size:12px;background:#ffffde;border:1px solid #aa3;border-radius:2px;pointer-events:none;z-index:100}#mermaid-1732378387752 .actor{stroke:#ccf;fill:#ececff}#mermaid-1732378387752 text.actor{fill:#000;stroke:none}#mermaid-1732378387752 .actor-line{stroke:grey}#mermaid-1732378387752 .messageLine0{marker-end:"url(#arrowhead)"}#mermaid-1732378387752 .messageLine0,#mermaid-1732378387752 .messageLine1{stroke-width:1.5;stroke-dasharray:"2 2";stroke:#333}#mermaid-1732378387752 #arrowhead{fill:#333}#mermaid-1732378387752 #crosshead path{fill:#333!important;stroke:#333!important}#mermaid-1732378387752 .messageText{fill:#333;stroke:none}#mermaid-1732378387752 .labelBox{stroke:#ccf;fill:#ececff}#mermaid-1732378387752 .labelText,#mermaid-1732378387752 .loopText{fill:#000;stroke:none}#mermaid-1732378387752 .loopLine{stroke-width:2;stroke-dasharray:"2 2";marker-end:"url(#arrowhead)";stroke:#ccf}#mermaid-1732378387752 .note{stroke:#aa3;fill:#fff5ad}#mermaid-1732378387752 .noteText{fill:#000;stroke:none;font-family:trebuchet ms,verdana,arial;font-size:14px}#mermaid-1732378387752 .section{stroke:none;opacity:.2}#mermaid-1732378387752 .section0{fill:rgba(102,102,255,.49)}#mermaid-1732378387752 .section2{fill:#fff400}#mermaid-1732378387752 .section1,#mermaid-1732378387752 .section3{fill:#fff;opacity:.2}#mermaid-1732378387752 .sectionTitle0,#mermaid-1732378387752 .sectionTitle1,#mermaid-1732378387752 .sectionTitle2,#mermaid-1732378387752 .sectionTitle3{fill:#333}#mermaid-1732378387752 .sectionTitle{text-anchor:start;font-size:11px;text-height:14px}#mermaid-1732378387752 .grid .tick{stroke:#d3d3d3;opacity:.3;shape-rendering:crispEdges}#mermaid-1732378387752 .grid path{stroke-width:0}#mermaid-1732378387752 .today{fill:none;stroke:red;stroke-width:2px}#mermaid-1732378387752 .task{stroke-width:2}#mermaid-1732378387752 .taskText{text-anchor:middle;font-size:11px}#mermaid-1732378387752 .taskTextOutsideRight{fill:#000;text-anchor:start;font-size:11px}#mermaid-1732378387752 .taskTextOutsideLeft{fill:#000;text-anchor:end;font-size:11px}#mermaid-1732378387752 .taskText0,#mermaid-1732378387752 .taskText1,#mermaid-1732378387752 .taskText2,#mermaid-1732378387752 .taskText3{fill:#fff}#mermaid-1732378387752 .task0,#mermaid-1732378387752 .task1,#mermaid-1732378387752 .task2,#mermaid-1732378387752 .task3{fill:#8a90dd;stroke:#534fbc}#mermaid-1732378387752 .taskTextOutside0,#mermaid-1732378387752 .taskTextOutside1,#mermaid-1732378387752 .taskTextOutside2,#mermaid-1732378387752 .taskTextOutside3{fill:#000}#mermaid-1732378387752 .active0,#mermaid-1732378387752 .active1,#mermaid-1732378387752 .active2,#mermaid-1732378387752 .active3{fill:#bfc7ff;stroke:#534fbc}#mermaid-1732378387752 .activeText0,#mermaid-1732378387752 .activeText1,#mermaid-1732378387752 .activeText2,#mermaid-1732378387752 .activeText3{fill:#000!important}#mermaid-1732378387752 .done0,#mermaid-1732378387752 .done1,#mermaid-1732378387752 .done2,#mermaid-1732378387752 .done3{stroke:grey;fill:#d3d3d3;stroke-width:2}#mermaid-1732378387752 .doneText0,#mermaid-1732378387752 .doneText1,#mermaid-1732378387752 .doneText2,#mermaid-1732378387752 .doneText3{fill:#000!important}#mermaid-1732378387752 .crit0,#mermaid-1732378387752 .crit1,#mermaid-1732378387752 .crit2,#mermaid-1732378387752 .crit3{stroke:#f88;fill:red;stroke-width:2}#mermaid-1732378387752 .activeCrit0,#mermaid-1732378387752 .activeCrit1,#mermaid-1732378387752 .activeCrit2,#mermaid-1732378387752 .activeCrit3{stroke:#f88;fill:#bfc7ff;stroke-width:2}#mermaid-1732378387752 .doneCrit0,#mermaid-1732378387752 .doneCrit1,#mermaid-1732378387752 .doneCrit2,#mermaid-1732378387752 .doneCrit3{stroke:#f88;fill:#d3d3d3;stroke-width:2;cursor:pointer;shape-rendering:crispEdges}#mermaid-1732378387752 .activeCritText0,#mermaid-1732378387752 .activeCritText1,#mermaid-1732378387752 .activeCritText2,#mermaid-1732378387752 .activeCritText3,#mermaid-1732378387752 .doneCritText0,#mermaid-1732378387752 .doneCritText1,#mermaid-1732378387752 .doneCritText2,#mermaid-1732378387752 .doneCritText3{fill:#000!important}#mermaid-1732378387752 .titleText{text-anchor:middle;font-size:18px;fill:#000}
#mermaid-1732378387752 g.classGroup text{fill:#9370db;stroke:none;font-family:trebuchet ms,verdana,arial;font-size:10px}#mermaid-1732378387752 g.classGroup rect{fill:#ececff;stroke:#9370db}#mermaid-1732378387752 g.classGroup line{stroke:#9370db;stroke-width:1}#mermaid-1732378387752 .classLabel .box{stroke:none;stroke-width:0;fill:#ececff;opacity:.5}#mermaid-1732378387752 .classLabel .label{fill:#9370db;font-size:10px}#mermaid-1732378387752 .relation{stroke:#9370db;stroke-width:1;fill:none}#mermaid-1732378387752 #compositionEnd,#mermaid-1732378387752 #compositionStart{fill:#9370db;stroke:#9370db;stroke-width:1}#mermaid-1732378387752 #aggregationEnd,#mermaid-1732378387752 #aggregationStart{fill:#ececff;stroke:#9370db;stroke-width:1}#mermaid-1732378387752 #dependencyEnd,#mermaid-1732378387752 #dependencyStart,#mermaid-1732378387752 #extensionEnd,#mermaid-1732378387752 #extensionStart{fill:#9370db;stroke:#9370db;stroke-width:1}#mermaid-1732378387752 .branch-label,#mermaid-1732378387752 .commit-id,#mermaid-1732378387752 .commit-msg{fill:#d3d3d3;color:#d3d3d3}</style><style>#mermaid-1732378387752{color:#000;font:normal normal 400 normal 16px / normal "Times New Roman"}</style><g></g><g><line id="actor0" x1="75" y1="5" x2="75" y2="220" class="actor-line" stroke-width="0.5px" stroke="#999"></line><rect x="0" y="0" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="75" y="32.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="75" dy="0">John</tspan></text></g><g><line id="actor1" x1="275" y1="5" x2="275" y2="220" class="actor-line" stroke-width="0.5px" stroke="#999"></line><rect x="200" y="0" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="275" y="32.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="275" dy="0">Alice</tspan></text></g><defs><marker id="arrowhead" refX="5" refY="2" markerWidth="6" markerHeight="4" orient="auto"><path d="M 0,0 V 4 L6,2 Z"></path></marker></defs><defs><marker id="crosshead" markerWidth="15" markerHeight="8" orient="auto" refX="16" refY="4"><path fill="black" stroke="#000000" stroke-width="1px" d="M 9,2 V 6 L16,4 Z" style="stroke-dasharray: 0, 0;"></path><path fill="none" stroke="#000000" stroke-width="1px" d="M 0,1 L 6,7 M 6,1 L 0,7" style="stroke-dasharray: 0, 0;"></path></marker></defs><g><text x="175" y="93" class="messageText" style="text-anchor: middle;">Hello John, how are you?</text><line x1="275" y1="100" x2="75" y2="100" class="messageLine0" stroke-width="2" stroke="black" marker-end="url(#arrowhead)" style="fill: none;"></line></g><g><text x="175" y="128" class="messageText" style="text-anchor: middle;">Great!</text><line x1="75" y1="135" x2="275" y2="135" class="messageLine1" stroke-width="2" stroke="black" marker-end="url(#arrowhead)" style="stroke-dasharray: 3, 3; fill: none;"></line></g><g><rect x="0" y="155" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="75" y="187.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="75" dy="0">John</tspan></text></g><g><rect x="200" y="155" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="275" y="187.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="275" dy="0">Alice</tspan></text></g></svg> </div> <h2 id="tweets">Tweets</h2> <p> An example of displaying a tweet: <div class='jekyll-twitter-plugin'><blockquote class="twitter-tweet"><p lang="sv" dir="ltr">jekyll-twitter-plugin (1.0.0): A Liquid tag plugin for Jekyll that renders Tweets from Twitter API <a href="http://t.co/m4EIQPM9h4">http://t.co/m4EIQPM9h4</a></p>&mdash; RubyGems (@rubygems) <a href="https://twitter.com/rubygems/status/518821243320287232?ref_src=twsrc%5Etfw">October 5, 2014</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> </p> <p> An example of pulling from a timeline: <div class='jekyll-twitter-plugin'><a class="twitter-timeline" data-width="500" data-tweet-limit="3" href="https://twitter.com/jekyllrb?ref_src=twsrc%5Etfw">Tweets by jekyllrb</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> </p> <p> For more details on using the plugin visit: <a href="https://github.com/rob-murray/jekyll-twitter-plugin">jekyll-twitter-plugin</a> </p> <h2 id="blockquotes">Blockquotes</h2> <blockquote> We do not grow absolutely, chronologically. We grow sometimes in one dimension, and not in another, unevenly. We grow partially. We are relative. We are mature in one realm, childish in another. —Anais Nin </blockquote> <h2 id="layouts">Layouts</h2> The main text column is referred to as the body. It's the assumed layout of any direct descendants of the `d-article` element. <div class="fake-img l-body"> <p>.l-body</p> </div> For images you want to display a little larger, try `.l-page`: <div class="fake-img l-page"> <p>.l-page</p> </div> All of these have an outset variant if you want to poke out from the body text a little bit. For instance: <div class="fake-img l-body-outset"> <p>.l-body-outset</p> </div> <div class="fake-img l-page-outset"> <p>.l-page-outset</p> </div> Occasionally you'll want to use the full browser width. For this, use `.l-screen`. You can also inset the element a little from the edge of the browser by using the inset variant. <div class="fake-img l-screen"> <p>.l-screen</p> </div> <div class="fake-img l-screen-inset"> <p>.l-screen-inset</p> </div> The final layout is for marginalia, asides, and footnotes. It does not interrupt the normal flow of `.l-body`-sized text except on mobile screen sizes. <div class="fake-img l-gutter"> <p>.l-gutter</p> </div> <h2 id="other-typography">Other Typography?</h2> <p> Emphasis, aka italics, with the <code>&lt;i&gt;&lt;/i&gt;</code> tag <i>emphasis</i>. </p> <p> Strong emphasis, aka bold, with <code>&lt;b&gt;&lt;/b&gt;</code> tag <b>bold</b>. </p> <p> Strikethrough ca be accomplished with the <code>&lt;s&gt;&lt;/s&gt;</code> tag. <s>Scratch this.</s> </p> <ul> <li>First ordered list item</li> <li>Another item</li> <ol> <li>Unordered sub-list. </li> </ol> <li>And another item.</li> </ul> <p> For code, the language can be specified in the class. For example, use <q>language-javascript</q> for Javascript and <q>language-python</q> for Python code. </p> <pre><code class="language-javascript">var s = "JavaScript syntax highlighting";
  alert(s);</code></pre> <pre><code class="language-python">s = "Python syntax highlighting"
  print(s)</code></pre> <pre><code class="language-python">No language indicated, so no syntax highlighting.</code></pre> <p> A table can be created with the <code>&lt;table&gt;</code> element. Below is an example </p> <table> <thead> <tr> <th>Tables</th> <th style="text-align: center">Are</th> <th style="text-align: right">Cool</th> </tr> </thead> <tbody> <tr> <td>col 3 is</td> <td style="text-align: center">right-aligned</td> <td style="text-align: right">$1600</td> </tr> <tr> <td>col 2 is</td> <td style="text-align: center">centered</td> <td style="text-align: right">$12</td> </tr> <tr> <td>zebra stripes</td> <td style="text-align: center">are neat</td> <td style="text-align: right">$1</td> </tr> </tbody> </table> <p> <blockquote>Blockquotes can be defined with the &gt;blockquote&lt; tag.</blockquote> </p>]]></content><author><name>Albert Einstein</name></author><summary type="html"><![CDATA[Your blog post's abstract. Please add your abstract or summary here and not in the main body of your text. Do not include math/latex or hyperlinks.]]></summary></entry><entry><title type="html">Parameter-Efficient and Stable Singular Value Adaptation for Pre-Trained Models</title><link href="https://iclr-blogposts.github.io/2025/blog/pessa/" rel="alternate" type="text/html" title="Parameter-Efficient and Stable Singular Value Adaptation for Pre-Trained Models"/><published>2025-04-28T00:00:00+08:00</published><updated>2025-04-28T00:00:00+08:00</updated><id>https://iclr-blogposts.github.io/2025/blog/pessa</id><content type="html" xml:base="https://iclr-blogposts.github.io/2025/blog/pessa/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>Fine-tuning large language models (LLMs) is highly effective for enhancing downstream task performance. However, fine-tuning very large models is costly. For instance, 16-bit fine-tuning of GPT-3 175B consumes 1.2 TB of VRAM <d-cite key="hu2021lora"></d-cite> , while LLaMA 65B model requires over 780 GB of GPU memory <d-cite key="dettmers2024qlora"></d-cite>. To address this, parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank Adaptation (LoRA) <d-cite key="hu2021lora"></d-cite>, have been developed to reduce memory usage and parameter requirements while maintaining performance without adding inference latency.</p> <p>Shuttleworth et al. <d-cite key="shuttleworth2024lora"></d-cite> recently analyzed how fine-tuning alter pre-trained models by examining the spectral properties of weight matrices. They found that LoRA introduces high-ranking singular vectors, termed ‘intruder dimensions’, which are absent in full fine-tuning. Models fine-tuned with LoRA tend to forget more of the pre-training distribution and show less robust continual learning compared to full fine-tuning.</p> <p>PiSSA <d-cite key="meng2024pissa"></d-cite> and SVFT <d-cite key="lingam2024svft"></d-cite> applies SVD to the pre-trained matrix. SVFT freezing the singular vectors and fine-tuning only the singular values. By avoiding the introduction of ‘intruder dimensions,’ this approach helps <strong>stabilize</strong> the training process. However, although it reduces the number of trainable parameters, decomposing a matrix $W \in \mathbb{R}^{m \times n}$ into orthogonal matrices $U \in \mathbb{R}^{m \times \text{min}(m,n)}$, and $V \in \mathbb{R}^{\text{min}(m,n) \times n}$, and diagonal matrix $S \in \mathbb{R}^{\text{min}(m,n)\times\text{min}(m,n)}$, introduces significant additional parameters and computational overhead. When m = n , this overhead exceeds $3\times$ the original cost. PiSSA slicing the principal singular values and singular vectors for fine-tuning while keeping the remaining components frozen. This avoids the twofold computational cost but limits adjustments to only part of the orthogonal bases.</p> <p>A key question then arises: how can we <strong>efficiently</strong> fine-tune within the latent space of pre-trained models?</p> <p>In this work, we observe that each attention layer naturally contains two pairs of matrices, $W_Q$ and $W_K^T$, as well as $W_V$ and $W_O$, which can be <strong>absorbed</strong> into head-wise low-rank matrices $W_{QK}\in\mathbb{R}^{h\times D\times D}$ and $W_{VO}\in\mathbb{R}^{h\times D\times D}$, where the ranks satisfy $r_{qk} \leq d$ and $ r_{vo} \leq d$. By <strong>decomposing</strong> $W_{QK}$ and $W_{VO}$ with SVD and removing singular vectors corresponding to zero singular values, we obtain orthogonal bases without increasing and even reducing the number of frozen parameters. These frozen bases maintain <strong>stability</strong> during fine-tuning, while the corresponding singular values, with minimal parameter overhead, enable <strong>efficient</strong> fine-tuning.</p> <p><strong>Summary of Contributions:</strong></p> <ol> <li>Orthogonalization via Absorb-Decompose: We discovered that the $W_Q$, $W_K$ and $W_V$,$W_O$ matrices in attention mechanisms can be orthonormalized through a Absorb-Decompose method. This transformation preserves the model’s original capabilities.</li> <li>Reducing Redundant Parameters: Orthogonalizing attention heads effectively eliminates redundant parameters. Applying Absorb-Decompose to the encoder of Whisper-large-v3 reduces 56.01% of the parameters in $W_Q$ and $W_K$, and 36.82% in $W_V$ and $W_O$, without any loss of performance, even without additional training.</li> <li>Efficient and Stable Fine-Tuning: By freezing the orthogonal bases and fine-tuning only their linear combinations, we introduce <strong>P</strong>arameter-<strong>E</strong>fficient and <strong>S</strong>table <strong>S</strong>ingular value <strong>A</strong>daptation (<strong>PESSA</strong>). Applying PESSA to fine-tune LLaMA-2-7B achieves an average improvement of 5.4% over LoRA and 4.4% over DoRA across 8 commonsense reasoning fine-tuning tasks.</li> </ol> <h1 id="related-works">Related Works</h1> <p><strong>LoRA</strong> <d-cite key="hu2021lora"></d-cite> integrates trainable adapters into linear layers, allowing these adaptations to be re-parameterized back into the standard model structure after fine-tuning. This approach has gained widespread adoption for its ability to preserve the model’s original architecture while enabling efficient fine-tuning. Building on LoRA, AdaLoRA <d-cite key="zhang2023adalora"></d-cite> dynamically learns the rank size required for LoRA in each model layer, optimizing parameter efficiency. DeltaLoRA <d-cite key="zi2023delta"></d-cite>enhances LoRA’s representational capacity by directly updating the original weights of the model using parameters from adapter layers. LoSparse <d-cite key="li2023losparse"></d-cite> incorporates LoRA to mitigate the risk of pruning overly expressive neurons. DoRA <d-cite key="liu2024dora"></d-cite> introduces a magnitude component to learn the scale of $\Delta W$, while using the original AB as the direction component of $\Delta W$.</p> <p><strong>PiSSA</strong> <d-cite key="meng2024pissa"></d-cite> focuses on the impact of initialization on gradient directions, firstly applying singular value decomposition (SVD) to the original matrix and fine-tuning the principal singular values and corresponding singular vectors. This initialization approach leads to faster convergence, improved performance, and reduced quantization error. Following PiSSA, LoRA-XS <d-cite key="balazy2024lora"></d-cite>, LaMDA <d-cite key="azizi2024lamda"></d-cite> and SVFT <d-cite key="lingam2024svft"></d-cite>, perform singular value decomposition on the original matrix, freezing the singular vectors while fine-tuning the singular values to reduces the trainable parameters. Among them, LoRA-XS and LaMDA fine-tune only a subset of singular values, while SVFT adjusts all singular values. OLoRA <d-cite key="buyukakyuz2024olora"></d-cite> leverages orthonormal matrix initialization through QR decomposition. CorDA <d-cite key="yang2024corda"></d-cite>, MiLoRA <d-cite key="wang2024milora"></d-cite>, LoRA-GA <d-cite key="wang2024loraga"></d-cite>, LoRA-Pro <d-cite key="wang2024lorapro"></d-cite>, and EVA <d-cite key="paischer2024one"></d-cite> utilize SVD in different ways to initialize adapters. CorDA and EVA decompose data for initialization, MiLoRA leverages the smaller singular values of matrices, while LoRA-GA and LoRA-Pro decompose the update directions from full fine-tuning. SVDQuant <d-cite key="li2024svdqunat"></d-cite> addresses outliers by shifting them from activations to weights and employs a high-precision low-rank branch to integrate the weight outliers using SVD.</p> <h1 id="parameter-efficient-and-stable-singular-value-adaptation">Parameter-Efficient and Stable Singular value Adaptation</h1> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-pessa/absorb-decompose-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-pessa/absorb-decompose-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-pessa/absorb-decompose-1400.webp"/> <img src="/2025/assets/img/2025-04-28-pessa/absorb-decompose.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">Figure 1. Workflow of Parameter-Efficient and Stable Singular Value Adaptation (PESSA). Frozen parameters are represented in blue, while trainable parameters are highlighted in orange. The left diagram illustrates a standard multi-head attention mechanism. In PESSA, we absorb $W_Q$, $W_K^T$ and $W_V$, $W_O$ into two low-rank matrices, $W_{QK}$ and $W_{VO}$, respectively. These matrices are then decomposed using SVD. The original attention head matrices are replaced by singular vectors associated with non-zero singular values, while the singular values are inserted between the vectors to enable fine-tuning. This transformation yields a module that is functionally equivalent to the original attention layer. </div> <h2 id="absorb-and-decompose">Absorb and Decompose</h2> <p>For Multi-Head Self-Attention, $X\in \mathbb{R}^{b\times n\times D}$, $W_Q\in \mathbb{R}^{D\times h\times d}$, $W_K\in \mathbb{R}^{D\times h\times d}$, $W_V\in \mathbb{R}^{D\times h\times d}$, $W_O\in \mathbb{R}^{h\times d\times D}$.</p> <p>Where $b$, $n$ and $D$ represent the batch size, the seqence length and the dimension of $X$. $h$ and $d$ is the number of heads and the dimension of head for $W_Q$, $W_K$ and $W_V$, $W_O$.</p> <p>The process of absorbing and decomposing $W_Q$ and $W_K$ can be represented as follows:</p> \[\text{attn(Q, K)}=\text{softmax}(\frac{QK^T}{\sqrt{d}}), \quad \text{$Q=XW_Q\in \mathbb{R}^{b\times h\times n\times d}$, $K=XW_K\in \mathbb{R}^{b\times h\times n\times d}.$}\] \[=\text{softmax}(\frac{XW_QW_K^TX^T}{\sqrt{d}}), \quad \text{$W_QW_K^{T}=W_{QK}\in \mathbb{R}^{h\times D\times D}.$}\] \[=\text{softmax}(\frac{XW_{QK}X^T}{\sqrt{d}}), \quad \text{$W_{QK}=USV=U_{[:,:,:r_{qk}]}S_{[:,:r_{qk},:r_{qk}]}V_{[:,:r_{qk},:]}=U_{QK}S_{QK}V_{QK}, r_{qk}\leq d.$}\] \[=\text{softmax}(\frac{XU_{QK}S_{QK}V_{QK}X^T}{\sqrt{d}}), \quad \text{$U_{QK}\in \mathbb{R}^{D\times h\times r_{qk}}$, $S_{QK}\in \mathbb{R}^{h\times r_{qk} \times r_{qk}}$, $V_{QK}\in \mathbb{R}^{h\times r_{qk} \times D}.$}\] <p>Through this series of transformations, $W_Q$ and $W_K$ can be equivalently replaced by orthogonal vectors $U_{QK}$ and $V_{QK}$, along with the diagonal matrix $S_{QK}$.</p> <p>The process of absorbing and decomposing $W_V$ and $W_O$ can be represented as follows:</p> \[Y=\text{attn(Q, K)}VW_O, \quad \text{$V=XW_V\in \mathbb{R}^{b\times h\times n\times d}$},\] \[=\text{attn(Q, K)}XW_VW_O, \quad \text{$W_VW_O=W_{VO}\in \mathbb{R}^{h\times D\times D}$}\] \[=\text{attn(Q, K)}XW_{VO}, \quad \text{$W_{VO}=USV=U_{[:,:,:r_{vo}]}S_{[:,:r_{vo},:r_{vo}]}U_{[:,:r_{vo},:]}=U_{VO}S_{VO}V_{VO}, r_{vo}\leq d$.}\] \[=\text{attn(Q, K)}XU_{VO}S_{VO}V_{VO}, \quad \text{$U_{VO}\in \mathbb{R}^{D\times h\times r_{vo}}$, $S_{VO}\in \mathbb{R}^{h\times r_{vo} \times r_{vo}}$, $V_{VO}\in \mathbb{R}^{h\times r_{vo} \times D}.$}\] <p>Through this series of transformations, $W_V$ and $W_O$ can be equivalently replaced by orthogonal vectors $U_{VO}$ and $V_{VO}$, along with the diagonal matrix $S_{VO}$.</p> <h2 id="parameter-efficient-and-stable-fine-tuning">Parameter-Efficient and Stable Fine-Tuning</h2> <p>The proposed Absorb-Decompose operation effectively reduces linear dependencies in $W_Q$, $W_K$, $W_V$, and $W_O$. During the decomposition of $W_{QK}$ and $W_{VO}$, it generates vectors with dimensions smaller than the head dimension, enabling a training-free pruning process.</p> <p>Unlike traditional pruning, which allows for lossy pruning followed by retraining to recover model accuracy, pruning large pre-trained models presents unique challenges. The pretraining of such models relies on vast, often inaccessible datasets. As a result, while retraining may achieve strong performance on certain benchmarks, it can fail on other tasks or even introduce safety risks. This makes training-free pruning particularly critical.</p> <p>Thanks to the Absorb-Decompose method, which orthogonalizes the original $W_Q$-$W_K$ and $W_V$-$W_O$ pairs in attention layers, we obtain a moderate number of singular values. For comparison, SVFT <d-cite key="hu2021lora"></d-cite> decomposes the entire matrix and produces singular values $S \in \mathbb{R}^{\text{min}(m, n) \times \text{min}(m, n)}$. One approach treats $S$ as a vector, significantly reducing the number of trainable parameters but limiting expressive capacity since it can only scale singular vectors without learning their linear combinations. Another approach considers $S$ as a full matrix, which, for attention layers where $m = n$ , results in a parameter size equivalent to the original matrix, making it less practical. To balance these trade-offs, SVFT adopts a sparse representation of $ S $, fine-tuning only its diagonal elements, a small boundary width, and a fixed sparse pattern. While this improves efficiency, it is less flexible than a structured format.</p> <p>Our proposed PESSA method strikes a balance between these extremes by learning head-wise singular values $S \in \mathbb{R}^{h \times d \times d}$, where $d$ is the attention head dimension. For instance, in LLaMA-2-7B, $h = 32$ and $d = 128$ , resulting in a parameter count comparable to a rank-$64$ LoRA configuration. PESSA allows orthogonal singular vectors within each head to freely combine, significantly enhancing expressive capacity.</p> <p>By leveraging the benefits of Absorb and Decompose operations, $W_Q$, $W_K$, $W_V$, and $W_O$ can be equivalently represented using smaller, mutually orthogonal singular vectors and their corresponding singular values. For parameter-efficient and stable fine-tuning, the gradients of the orthogonal bases are frozen and used only in the forward pass, while only the singular values are fine-tuned, enabling updates within the latent space of the pre-trained model.</p> <p>Due to the RoPE <d-cite key="su2024roformer"></d-cite> applied between $W_Q$ and $W_K$ in LLaMA-2-7B, the Absorb-Decompose operation cannot be directly applied. For such cases, we replace SVD with QR decomposition and decompose $W_Q$ and $W_K$ into orthogonal matrices and upper triangular matrices. We freeze the orthogonal matrices and fine-tune the upper triangular matrices. Combined with the singular value matrix obtained by performing Absorb-Decompose on $W_V$ and $W_O$, the total number of trainable parameters in this setup is equivalent to fine-tuning $W_Q$, $W_K$, and $W_V$ with rank-$64$ LoRA.</p> <p>Using PESSA for fine-tuning requires reinitializing the model only at the start. After training, $S_{QK}$ and $S_{VO}$ can be merged back into $U_{QK}$ and $U_{VO}$, ensuring no additional inference overhead.</p> <h1 id="experiment">Experiment</h1> <h2 id="absorb-decompose-for-pruning">Absorb-Decompose for Pruning</h2> <p>We selected the Whisper-large-v3 model <d-cite key="radford2023robust"></d-cite>, a Transformer-based encoder-decoder architecture with 1.55 billion parameters. It is trained simultaneously on multilingual speech recognition and speech translation tasks. We applied the Absorb-Decompose method across all 32 attention layers in the encoder. Figure 2 illustrates the singular values $S_{QK}$ obtained through this method. For comparison, we also computed the Euclidean norm for each dimension and ranked them in descending order within each attention head.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-pessa/pruning-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-pessa/pruning-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-pessa/pruning-1400.webp"/> <img src="/2025/assets/img/2025-04-28-pessa/pruning.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Figure 2: The $L_2$-norm for the 0-th, 15-th, and 31-st attention layers in the Whisper-large-v3 encoder. The blue line represents the results after redundancy removal using the Absorb-Decompose method, while the orange line depicts the $L_2$-norm directly computed for each dimension.</p> <p>As shown in Figure 2, although the $L_2$-norms for dimensions in the 0-th and 15-th layers are small, their distribution across dimensions is relatively uniform, with less dimension reduced to zero. Removing such dimensions indiscriminately could significantly harm model performance. In contrast, the Absorb-Decompose method concentrates these parameters into a small subset of bases, resulting in many singular values being reduced to zero. This allows their corresponding singular vectors to be safely pruned.</p> <p>We also observed that different layers exhibit varying degrees of low-rank properties. Early layers tend to have higher redundancy, while later layers contain more task-relevant independent vectors. To address this, we applied a unified, small threshold across all layers. Singular values below this threshold, along with their corresponding singular vectors, were pruned. Our findings demonstrate that the Absorb-Decompose method enables a high rate of training-free pruning, effectively reducing model complexity without compromising its performance.</p> <p>Next, we present an example to intuitively demonstrate the effectiveness of this training-free pruning approach. We use a audio input from the librispeech_long dataset <d-cite key="gandhi2023distil"></d-cite>. The waveform of this input is visualized in Figure 3 for reference.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2025/assets/img/2025-04-28-pessa/audio-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2025/assets/img/2025-04-28-pessa/audio-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2025/assets/img/2025-04-28-pessa/audio-1400.webp"/> <img src="/2025/assets/img/2025-04-28-pessa/audio.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>We first use Whisper-large-v3 directly to recognize the audio. The baseline recognition output is as follows:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. 
Nor is Mr. Quilter's manner less interesting than his matter. 
He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. 
He has grave doubts whether Sir Frederick Layton's work is really Greek after all, and can discover in it but little of rocky Ithaca. 
Linnell's pictures are a sort of Up Guards and Adam paintings, and Mason's exquisite idles are as national as a jingo poem. 
Mr. Birkett Foster's landscapes smile at one much in the same way that Mr. Carker used to flash his teeth, and Mr. John Collier gives his sitter a cheerful slap on the back before he says, like a shampooer in a Turkish bath, next man.
</code></pre></div></div> <p>Applying Absorb-Decompose to orthogonalize the Attention Head introduces an equivalent transformation. If the near-zero singular values and their corresponding singular vectors are not removed, the model’s output remains completely unchanged.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. 
Nor is Mr. Quilter's manner less interesting than his matter. 
He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. 
He has grave doubts whether Sir Frederick Layton's work is really Greek after all, and can discover in it but little of rocky Ithaca. 
Linnell's pictures are a sort of Up Guards and Adam paintings, and Mason's exquisite idles are as national as a jingo poem. 
Mr. Birkett Foster's landscapes smile at one much in the same way that Mr. Carker used to flash his teeth, and Mr. John Collier gives his sitter a cheerful slap on the back before he says, like a shampooer in a Turkish bath, next man.
</code></pre></div></div> <p>After applying the Absorb-Decompose method, we pruned singular values and their corresponding singular vectors with magnitudes close to zero ($S_{QK}\leq 5e^{-3}$ and $S_{VO}\leq 6e^{-3}$). This resulted in pruning ratios of 56.01% and 36.82% for the parameters in $W_Q$-$W_K$ and $W_V$-$W_O$, respectively. Remarkably, the model’s output remains nearly unchanged:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. 
Nor is Mr. Quilter's manner less interesting than his matter. 
He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. 
He has grave doubts whether Sir Frederick Layton's work is really Greek after all, and can discover in it but little of rocky Ithaca. 
Linnell's pictures are a sort of Up Guards and Adam paintings, and Mason's exquisite idles are as national as a jingo poem. 
Mr. Birkett Foster's landscapes smile at one much in the same way that Mr. Carker used to flash his teeth. And Mr. John Collier gives his sitter a cheerful slap on the back before he says, like a shampooer in a Turkish bath, next man.
</code></pre></div></div> <p>In contrast, using a vanilla pruning method with the same pruning ratio, the model completely fails to produce valid outputs:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 
</code></pre></div></div> <p>In fact, with Vanilla Pruning ratios of just 22.31% and 6.69% for $W_Q$-$W_K$ and $W_V$-$W_O$, respectively, the model’s output is already significantly degraded.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Mr. Colter is the personal of the classes, and we are glad to welcome his gospel. 
Nor is Mr. Colter's manner less interesting than his manner. 
He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similarly he is drawn from eating and its results occur most readily to the mind. 
He is very dull, so very frequently, and is very Greek after all, and can discover in it but little of Rocky Ithaca. 
The Nell's pictures are sort of up-guard to Adam's paintings, and Mason's exquisite idylls are as national as a jingle poem. 
Mr. Burke and Foster's landscapes smile at one much in the same way as Mr. Parker, Mr. Flash is tits. And Mr. John Collier gives his sitter a cheerful slap on the back before he says like a shampoo and a Turkish bath, Next man.
</code></pre></div></div> <p>This example validates our earlier statement that pruning a large number of non-zero dimensions accumulates loss, requiring fine-tuning to restore performance. In contrast, our Absorb-Decompose method losslessly consolidates parameters into a compact subspace, allowing the remaining directions to be freely pruned. By combining pruning with fine-tuning, training can be conducted with fewer resources directly within the latent space of the pre-trained model.</p> <h2 id="absorb-decompose-for-fine-tuning">Absorb-Decompose for Fine-Tuning</h2> <p>In this section, we evaluate PESSA against Full-Parameter Fine-tuning, LoRA <d-cite key="hu2021lora"></d-cite> and DoRA <d-cite key="liu2024dora"></d-cite> on LLaMA-2-7B for commonsense reasoning tasks. We did not compare with SVFT <d-cite key="lingam2024svft"></d-cite> due to its significant additional overhead. Commonsense reasoning tasks are divided into eight sub-tasks, detailed in Table 1. Following the DoRA setup, we fine-tune the combined Commonsense-170k dataset and evaluate the individual test set for each sub-task.</p> <p>Table 1: Details of datasets being evaluated.</p> <table> <thead> <tr> <th>Dataset</th> <th># train</th> <th># test</th> <th>About</th> </tr> </thead> <tbody> <tr> <td>BoolQ</td> <td>9.4K</td> <td>3,270</td> <td>Naturally occurring yes/no questions from unconstrained settings.</td> </tr> <tr> <td>PIQA</td> <td>16.1K</td> <td>1,830</td> <td>Questions with two solutions requiring physical commonsense.</td> </tr> <tr> <td>SIQA</td> <td>33.4K</td> <td>1,954</td> <td>Reasoning about actions and social implications.</td> </tr> <tr> <td>HellaSwag</td> <td>39.9K</td> <td>10,042</td> <td>Commonsense NLI questions with context and endings.</td> </tr> <tr> <td>WinoGrande</td> <td>63.2K</td> <td>1,267</td> <td>Fill-in-the-blank task with binary options requiring commonsense reasoning.</td> </tr> <tr> <td>ARC-e</td> <td>1.1K</td> <td>2,376</td> <td>Grade-school multiple-choice science questions in Easy sets.</td> </tr> <tr> <td>ARC-c</td> <td>2.3K</td> <td>1,172</td> <td>Grade-school multiple-choice science questions in Challenge sets.</td> </tr> <tr> <td>OBQA</td> <td>5.0K</td> <td>500</td> <td>Questions requiring multi-step reasoning and commonsense knowledge.</td> </tr> </tbody> </table> <p>For a fair comparison, we adopt the hyperparameter settings of DoRA (Table 2). The total number of trainable parameters in this setup is equivalent to fine-tuning $W_Q$, $W_K$, and $W_V$ using rank-$64$ LoRA.</p> <p>Table 2. Detailed Training Hyperparameters. Q$^\dagger$ and K$^\dagger$ are derived by applying QR decomposition to $W_Q$ and $W_K$, while V$^\ddagger$ is obtained by applying SVD to $W_V$ and $W_O$. Only the upper triangular and diagonal matrices are fine-tuned, while orthogonal matrices remain frozen. 64$^\ast$ indicates that PESSA’s tunable parameters match LoRA with rank 64.</p> <table> <thead> <tr> <th> </th> <th>Rank</th> <th>Alpha</th> <th>Dropout</th> <th>LR</th> <th>LR Scheduler</th> <th>Batch size</th> <th>Warmup Steps</th> <th>Epochs</th> <th>Target</th> </tr> </thead> <tbody> <tr> <td>LoRA</td> <td>64</td> <td>128</td> <td>0.05</td> <td>3e-4</td> <td>Linear</td> <td>16</td> <td>100</td> <td>3</td> <td>Q,K,V</td> </tr> <tr> <td>DoRA</td> <td>64</td> <td>128</td> <td>0.05</td> <td>2e-4</td> <td>Linear</td> <td>16</td> <td>100</td> <td>3</td> <td>Q,K,V</td> </tr> <tr> <td>PESSA</td> <td>64$^\ast$</td> <td>—</td> <td>—</td> <td>1e-4</td> <td>Linear</td> <td>16</td> <td>100</td> <td>3</td> <td>Q$^\dagger$,K$^\dagger$,V$^\ddagger$</td> </tr> </tbody> </table> <p>The experimental results of different methods are presented in Table 3. DoRA introduces a magnitude module, adding a small number of trainable parameters on top of LoRA, under the same rank. Additionally, as the dimension norm needs to be computed at every step, DoRA’s training speed is significantly slower than LoRA’s—approximately half the speed on a single A800 GPU we used. In contrast, PESSA only performs an initialization operation at the start of training, resulting in a training speed similar to LoRA. In this experiment, we did not prune redundant singular vectors. We believe that incorporating this training-free pruning technique could significantly reduce the number of frozen parameters, enabling more efficient training.</p> <p>Table 3. Accuracy on eight commonsense reasoning tasks, with LLaMA-2-7B as the base model. <strong>bold</strong> indicates the highest accuracy.</p> <table> <thead> <tr> <th>Method</th> <th>Params</th> <th>BoolQ</th> <th>PIQA</th> <th>SIQA</th> <th>HellaSwag</th> <th>WinoGrande</th> <th>ARC-e</th> <th>ARC-c</th> <th>OBQA</th> <th>Avg.</th> </tr> </thead> <tbody> <tr> <td>LoRA</td> <td>0.74%</td> <td>70.9</td> <td>81.3</td> <td>79.3</td> <td>87.8</td> <td>80.3</td> <td>80.6</td> <td>66.0</td> <td>80.0</td> <td>78.3</td> </tr> <tr> <td>DoRA</td> <td>0.75%</td> <td>71.1</td> <td>82.4</td> <td>78.1</td> <td>90.2</td> <td>81.4</td> <td>82.7</td> <td>68.5</td> <td>80.0</td> <td>79.3</td> </tr> <tr> <td>PESSA</td> <td>0.74%</td> <td><strong>74.3</strong></td> <td><strong>85.7</strong></td> <td><strong>81.1</strong></td> <td><strong>94.4</strong></td> <td><strong>85.9</strong></td> <td><strong>88.4</strong></td> <td><strong>74.9</strong></td> <td><strong>84.6</strong></td> <td><strong>83.7</strong></td> </tr> </tbody> </table> <p>From Table 3, our PESSA method significantly outperforms both LoRA and DoRA. For instance, PESSA achieves approximately 8% higher accuracy than LoRA and 6% higher than DoRA on ARC-easy and ARC-challenge tasks. On average, PESSA outperforms LoRA by 5.4% and DoRA by 4.4%. This notable improvement demonstrates the effectiveness of our approach, which fixes the orthogonal basis of the pre-trained model and learns its linear combinations.</p> <h1 id="limitations">Limitations</h1> <p>While Absorb-Decompose primarily supports Self-Attention, it also extends to Cross-Attention and cases where the input dimensions of $W_Q$ and $W_K$ differ, or the input dimension of $W_V$ differs from the output dimension of $W_O$. Additionally, it supports Causal Mask, Sliding Window mechanisms, and Linear layers with bias. However, the method currently does not support scenarios where nonlinear operations, such as ROPE or QK norm, exist between $W_Q$ and $W_K$. For these cases, we replace SVD with QR decomposition and directly decompose it by heads into an orthogonal matrix $Q$ and fine-tune the upper triangular matrix $R$.</p> <h1 id="conclusion">Conclusion</h1> <p>In this paper, we highlight the importance of freezing the orthogonal basis and fine-tuning their linear combinations to improve the stability of pre-trained model fine-tuning. We analyze the trade-off between efficiency and stability in existing methods and propose the absorb-decompose operation to achieve a balance between the two. Which removes linearly dependent bases in attention heads, enabling training-free pruning of 46.42% of the parameters in the Whisper-large-v3 encoder attention. By fine-tuning a subset of singular values with moderate parameter counts and strong expressive power, our PESSA method outperforms LoRA by 5.4% on eight commonsense reasoning tasks. We believe this approach is valuable for both PEFT and pruning, while also providing insights into the attention mechanism and the fine-tuning process of large models.</p>]]></content><author><name>Anonymous</name></author><summary type="html"><![CDATA[We observe that the Q, K, O, and V matrices in attention layers can inherently be absorbed and decomposed into four head-wise orthogonal matrices and two sets of singular values without any loss. After orthogonalization, we freeze the singular vectors and fine-tune only the singular values, enabling stable fine-tuning constrained to the original latent space, which achieves a 5.4% improvement over LoRA across eight commonsense reasoning datasets. Additionally, this absorb-decompose operation eliminates redundant vectors losslessly and reduces the encoder parameters of Whisper-large-v3 by 46.42% without requiring additional training.]]></summary></entry></feed>